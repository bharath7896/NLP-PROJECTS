Name : Ch Bharadwaj

APPROACH: 
       The given problem is distractor generation using supervised learning.
       So it is more of ranking distractor text based on the training data similarity measure.
       The feature modelling is done based on similarity measures like 1.Embedding similarity  2.Token similarity  3.Pos similarity 4.frequency
       of a(answers), q(questions), {di} (set of distractors).
       The following are assigned according to similarity ranking and SGD ranking .
       The text is generated by Ranking of r(d/sim(D,a,q)).
Preprocessing:
        For Q and A general preprocessing with removing puntuations and cleaninig text 
        For di there should be set of 3 distractors for  each Q A pair but the train data consisted of 1-15 options thus they fall under 2 categories
        1.di>3 and 2.di<3 for case:1 I took upto 5 because they comrised of huge amount of data then other high valeus , the main reason for these are 
        i. detection as different sentences due to punctuations , ii. due to repetation of the options , removing duplicates were done by clearing the 
        sentence with counter value greater than 1 .  after that the remaining high count set were reduced by conditional concatenation of sentences.
        for 2. where there were less options I added 'None of the above' and 'All of the above' to complete the analogy .
        Preprocessing was really challenging as there were many cases for inappropriate increment and decrement of the distractors.
      
	Note: Here we cannot afford much data loss or dropping becasue it may downgrade the distractor generated or predicted distractors quality.